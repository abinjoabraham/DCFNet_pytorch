{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCN on Sequential MNIST",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abinjoabraham/DCFNet_pytorch/blob/master/TCN_on_Sequential_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4QSips_y4th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sample_data.utils import data_generator\n",
        "from sample_data.model import TCN\n",
        "import numpy as np\n",
        "import argparse\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL_xhx3tf3G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixRzq2Pa149",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1111)\n",
        "if torch.cuda.is_available():\n",
        "   if not True:\n",
        "      print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "root = './_sample_data/mnist'\n",
        "batch_size = 64\n",
        "n_classes = 10\n",
        "input_channels = 1\n",
        "seq_length = int(784 / input_channels)\n",
        "epochs = 2\n",
        "steps = 0\n",
        "permuter = False\n",
        "seed = 1111\n",
        "nhid = 25\n",
        "optimi = 'Adam'\n",
        "lr = 2e-3\n",
        "loginterval = 100\n",
        "levels = 8\n",
        "cuda = True\n",
        "clip = -1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTF_ot_o7LRo",
        "colab_type": "code",
        "outputId": "7604852c-e54c-4a97-b091-8478cbd654b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install tensorboardX\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLK1s0P1bsAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader = data_generator(root, batch_size)\n",
        "permute = torch.Tensor(np.random.permutation(784).astype(np.float64)).long()\n",
        "channel_sizes = [25] * 8\n",
        "kernel_size = 7\n",
        "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=0.05)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia-3dJeXbvJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "  permute = permute.cuda()\n",
        "\n",
        "lr = 2e-3\n",
        "optimizer = getattr(optim, optimi)(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmj8b8O6cC-g",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc59BK53y_Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(ep):\n",
        "    global steps\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    #writer = SummaryWriter()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        if cuda: data, target = data.cuda(), target.cuda()\n",
        "        data = data.view(-1, input_channels, seq_length)\n",
        "        if permuter:\n",
        "            data = data[:, :, permute]\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        #writer.add_graph(model, data, True)             # model, input\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #writer.add_scalar('lossfunction', loss, batch_idx)\n",
        "        loss.backward()\n",
        "        # writer.add_image('data/scalar1', data, batch_idx)\n",
        "        # writer.add_image('data/scalar2', target, batch_idx)\n",
        "        if clip > 0:\n",
        "            torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
        "        optimizer.step()\n",
        "        train_loss += loss\n",
        "        steps += seq_length\n",
        "        if batch_idx > 0 and batch_idx % loginterval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tSteps: {}'.format(\n",
        "                ep, batch_idx * batch_size, len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), train_loss.item()/loginterval, steps))\n",
        "            train_loss = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6LfP8-RcqS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data = data.view(-1, input_channels, seq_length)\n",
        "        if permuter:\n",
        "            data = data[:, :, permute]\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    return test_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTdOOY4bcsuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "531a1970-7a61-445b-f4f3-03a8eb979644"
      },
      "source": [
        "    for epoch in range(1, epochs+1):\n",
        "        train(epoch)\n",
        "        test()\n",
        "        if epoch % 10 == 0:\n",
        "            lr /= 10\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.135190\tSteps: 79184\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.467878\tSteps: 157584\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.321196\tSteps: 235984\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.260094\tSteps: 314384\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.235185\tSteps: 392784\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.216135\tSteps: 471184\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.212920\tSteps: 549584\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.204784\tSteps: 627984\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.184365\tSteps: 706384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1504, Accuracy: 9509/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.143648\tSteps: 814576\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.158009\tSteps: 892976\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.145578\tSteps: 971376\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.135736\tSteps: 1049776\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.135413\tSteps: 1128176\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.131401\tSteps: 1206576\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.132465\tSteps: 1284976\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.139712\tSteps: 1363376\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.114955\tSteps: 1441776\n",
            "\n",
            "Test set: Average loss: 0.0918, Accuracy: 9696/10000 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}